{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing files lika a pro\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Generate a `DOCX` file with fake content\n",
    "- Generate 1 `DOCX` file with fake content (generated by `Faker`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/tmpg2pimppq.docx\n",
      "/tmp/tmp/tmpg2pimppq.docx\n",
      "Western onto dark hit effect. Help individual college. Room gun memory sit finally country become.\n",
      "Bag program fear event prevent bring nation close. Low night usually nearly card begin play artist.\n",
      "Necessary show air less big positive. Tree letter level rich relationship long put. Beyond quite none weight never economic always.\n",
      "Myself computer return total example training country more. Amount interview upon condition theory so attention. How hotel nor state country town.\n",
      "Film figure open.\n",
      "Pretty share law east. Perhaps hot woman bag question. School lawyer matter out development use edge.\n",
      "List cell guess listen new new. And remember senior speak where ball.\n",
      "Special Mrs practice nice. Wonder card about throw building individual as blue.\n",
      "Indicate skin down. Agreement consider spend learn act arm forward. Day modern college face.\n",
      "Yard street even strategy. Might soon receive difficult occur.\n",
      "Couple fast effect always. Control dream public energy. Choose democratic thank expert.\n",
      "Street stand dog. Difference laugh cold particularly join during social. List shoulder include small check resource.\n",
      "Hair represent difference strong or operation. Kitchen car whole fill old ok where.\n",
      "Future industry true establish give kind early film. Public purpose traditional agree leg agency remain.\n",
      "Window teach price per successful. Describe million surface player mention each. Financial black question.\n",
      "Continue report daughter pass back station subject suddenly. Popular manage loss avoid here free across PM.\n",
      "Wind marriage get create Congress really. Fact television challenge whole.\n",
      "Dark and Mrs should and behind officer. Keep outside against person. School beyond marriage soon vote.\n",
      "Cold ever seven size management reason including direction. Benefit a information play young road girl. Writer product visit that read tonight.\n",
      "Visit new investment most. Do activity value table. Recognize natural society play activity early practice.\n",
      "Week prove a article walk. Senior professor pressure election eight heavy catch.\n",
      "Maintain full suggest beautiful member plant military.\n",
      "Black support write what. Song by middle similar enough machine.\n",
      "Rise real occur car risk whatever. City million say size. Agreement local book member view.\n",
      "Market effect actually stuff meeting be. Write report instead guess education evening. Move lot along news key.\n",
      "Represent above bar machine. Detail truth grow rather catch mind free offer. Act hotel test Democrat.\n",
      "Walk real project challenge. Word operation wide church make.\n",
      "Expect scientist decide yard tend event section. International shake believe lay issue buy return far.\n",
      "Fill tell question tax food organization result. Lay employee food time. Section short another somebody seven state.\n",
      "Economy education only. Hospital compare later policy dream.\n",
      "Continue finally hour under least fund. Huge these make write simple ten scientist. Early security rest grow after.\n",
      "Sign method friend today hair. Student on together beat. Reflect executive stage thing mother challenge yard increase.\n",
      "Style reason very system. Hair drive movement finish. Result woman no sure range worker figure.\n",
      "Possible alone season why environmental score these. Thing myself lay early daughter reach charge week. Against any couple continue movement major together. Speak television get mean.\n",
      "Stay occur price reveal fish trip project. Respond wrong evening notice probably. Reason protect any thing only environmental opportunity.\n",
      "Player arrive he experience down phone court our. Majority past seven mission stop prevent adult.\n",
      "Car better deep charge exist cultural sing. Standard program old though.\n",
      "Fast might because month explain. Certain town college professor Democrat public. Hope law she southern man. Detail senior material rate range receive.\n",
      "Option area up school certain him skill. Become heart career only.\n",
      "Heart try sort either stop happen. Control fear form score company tree.\n",
      "Ground meeting pretty nothing big team. Same nor office pressure lead never interest.\n",
      "Last clearly door notice yourself. Room such front fish. Call state game main bad along.\n",
      "Number both spring because land. Away center leg view. Rather commercial expert inside reality different.\n",
      "Keep month suffer always reach. Dark social democratic performance.\n",
      "Sense traditional loss clearly. Quickly fall amount evening study.\n",
      "It take first friend attack more true. Subject nothing indeed report positive.\n",
      "Choose fast stock place woman us. Participant recently painting. Free call boy could report. Baby tree maintain most.\n",
      "Idea ask several. Guy firm six.\n",
      "Area character opportunity executive. Ability benefit bill might avoid.\n",
      "Condition student future special door look feel. Difficult must toward visit bill. Night understand those risk nature control.\n",
      "Easy cover stock information no stuff baby. First worker international management. Guy walk avoid least surface. Face get everything remain.\n",
      "Other against no lead despite fine race. Federal support garden understand purpose. Level success play history matter need song.\n",
      "Your office business rest experience. If little get sport on. Road consider nature lose strong skin pressure.\n",
      "My soldier modern mother guess office yard agreement.\n",
      "Fight need detail. Government rich protect machine.\n",
      "Society tough beautiful fire her woman. Change phone they.\n",
      "Fast drop idea oil. Someone girl year meeting carry.\n",
      "Officer interview us success gun center school. Trip medical above according.\n",
      "Result training artist kid. Suddenly activity require room.\n",
      "In along second ok. Write standard officer tell beautiful interview.\n",
      "Share will his son include difference. Character high subject again party above assume.\n",
      "Painting yes similar hundred mouth.\n",
      "School win town resource perhaps. Nothing age receive as. Situation behind probably sure study race itself.\n",
      "Study bar herself have bill father apply. Maybe four their your. Focus water lawyer recently.\n",
      "Four force interesting lay pick attention than religious. Glass necessary itself.\n",
      "Want name set attack. Look film check recognize agent. Record as surface these through much. Southern conference baby office along.\n",
      "Similar event listen writer exactly. Few beyond laugh expect hope.\n",
      "List deal case country phone feel free. Mother detail believe maybe treatment. Money as that story manager job.\n",
      "Daughter old success similar.\n",
      "Population brother sit as indicate. Employee political factor analysis step school.\n",
      "Source fund establish measure go animal. Almost represent president hotel. Decide find international.\n",
      "Bag physical close budget. Magazine what girl both outside add response. Without former all approach year. Exist listen economy up whose be next.\n",
      "When situation institution give take. Increase page meet serious customer kid.\n",
      "One none song process.\n",
      "Stock likely town itself sit history worker. Article crime teacher everything. Teacher put down must Mrs against west mother.\n",
      "Class sister on gas water wide story raise. Today board memory million since. Lose example business very visit language.\n",
      "Authority stage inside place. Effect everyone able senior.\n",
      "South performance impact building choice main government. Mission reality draw.\n",
      "Style seven public soldier. Report sense decision center. Leg yet phone position sound.\n",
      "Note range western side simply when entire. Trip both leave lawyer catch third. Hospital thus stage experience response.\n",
      "Thus happy board finish mean lay year. Meet time over provide age little why general.\n",
      "Deal crime yes laugh. Every piece worker guy building huge add.\n",
      "Imagine Congress exist seat discuss miss beat. Visit share development enough ahead eat eight start. Three weight along magazine.\n",
      "Unit federal certain until information apply within. Effect story level and live enough.\n",
      "Financial ability federal matter. Learn remember drug although everything. Employee stay test respond.\n",
      "North every perform ready forget future follow six. Speak worker term expert no from represent majority. Room against despite expect up.\n",
      "Factor natural wide shoulder left reason. Generation these sea range. Mouth beat benefit media how office none produce.\n",
      "Camera arrive quickly himself. Join simple need something specific ok similar.\n",
      "Everyone real get product state. White possible information surface relationship.\n",
      "Situation whom father open him research face offer. Speech air effort eye participant. Expect affect section show paper.\n",
      "Computer though like what partner herself room. Present of experience perhaps west young.\n",
      "Drug film better president manager. Address financial join.\n",
      "Responsibility stock strategy same single. Still not light mouth list must black.\n",
      "State instead difference meeting business. Involve author oil as suddenly.\n",
      "First while performance necessary design avoid soon.\n",
      "Easy likely recently free. Team meeting off stand either. Cup certain key audience.\n",
      "Course hundred also community team that. Must into ok it present choice member.\n",
      "Call participant likely general director return. Loss improve figure whom. Apply company not bar.\n",
      "Analysis board public response.\n",
      "Generation beat indicate become stuff. Challenge add cell detail land. Protect fly detail toward.\n",
      "Whether rate involve American at issue. Million since some garden respond once significant consumer.\n",
      "Still return mention of remain boy. Thus building set could. Western investment such people hold myself game.\n",
      "Dream including issue. Mr during at smile.\n",
      "Camera enter state baby foot like man environmental. Last yard public edge over.\n",
      "Trial cut population whole protect before. Southern morning budget maintain area. Oil could including after own reason.\n",
      "Smile agent amount law out. Good television magazine north security even.\n",
      "Study begin threat soldier. Blood owner administration direction much. Dark consider minute can husband minute.\n",
      "About political keep moment degree find child. Usually great late must offer think drug.\n",
      "Game Democrat industry any run over paper. Also to reality investment dinner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impact do create contain chair. Left old do despite media. Picture main wait.\n"
     ]
    }
   ],
   "source": [
    "# Import the Faker class from faker package\n",
    "from faker import Faker\n",
    "\n",
    "# Import the file provider we want to use\n",
    "from faker_file.providers.docx_file import DocxFileProvider\n",
    "\n",
    "FAKER = Faker()  # Initialise Faker instance\n",
    "\n",
    "FAKER.add_provider(DocxFileProvider)  # Register the DOCX file provider\n",
    "\n",
    "file = FAKER.docx_file()  # Generate a DOCX file\n",
    "\n",
    "# This is just a string-like value, with a relative path to the file\n",
    "print(file)\n",
    "\n",
    "# Note, that `file` is this case is an instance of either `StringValue`\n",
    "# or `BytesValue` objects, which inherit from `str` and `bytes`\n",
    "# respectively, but add meta data. Meta data is stored inside the `data`\n",
    "# property (`Dict`). One of the common attributes of which (among all\n",
    "# file providers) is the `filename`, which holds an absolute path to the\n",
    "# generated file.\n",
    "print(file.data[\"filename\"])\n",
    "\n",
    "# Another common attribute (although it's not available for all providers)\n",
    "# is `content`, which holds the text used to generate the file with.\n",
    "print(file.data[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide content manually\n",
    "- Generate 1 `DOCX` file with developer defined content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/tmpme178vtq.docx\n",
      "\n",
      "“The Queen of Hearts, she made some tarts,\n",
      "    All on a summer day:\n",
      "The Knave of Hearts, he stole those tarts,\n",
      "    And took them quite away.”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The text we want have in our generated DOCX file\n",
    "TEXT = \"\"\"\n",
    "“The Queen of Hearts, she made some tarts,\n",
    "    All on a summer day:\n",
    "The Knave of Hearts, he stole those tarts,\n",
    "    And took them quite away.”\n",
    "\"\"\"\n",
    "\n",
    "# Generate a DOCX file with the given text\n",
    "file = FAKER.docx_file(content=TEXT)\n",
    "\n",
    "print(file)\n",
    "print(file.data[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide templated content\n",
    "\n",
    "You can generate documents from pre-defined templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/tmpqivpfce_.pdf\n",
      "\n",
      "1993-12-20 West Virginia, Cook Islands\n",
      "\n",
      "Hello Christopher Hampton,\n",
      "\n",
      "Along state\n",
      "certain travel claim somebody mother. Play building all administration. General\n",
      "back surface involve ground be.\n",
      "\n",
      "Address: 8745 Abigail Ford Apt. 293\n",
      "Josephshire, SC 21143\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Lance Williams\n",
      "23879 Shannon River Apt.\n",
      "836\n",
      "Obrienchester, OK 94727\n",
      "105.812.3048x64112\n"
     ]
    }
   ],
   "source": [
    "from faker_file.providers.pdf_file import PdfFileProvider\n",
    "\n",
    "FAKER.add_provider(PdfFileProvider)  # Add the PDF file provider\n",
    "\n",
    "# The template. All standard Faker providers are available.\n",
    "TEMPLATE = \"\"\"\n",
    "{{date}} {{city}}, {{country}}\n",
    "\n",
    "Hello {{name}},\n",
    "\n",
    "{{text}}\n",
    "\n",
    "Address: {{address}}\n",
    "\n",
    "Best regards,\n",
    "\n",
    "{{name}}\n",
    "{{address}}\n",
    "{{phone_number}}\n",
    "\"\"\"\n",
    "\n",
    "# Note, that wrap_chars_after will automatically insert newline \n",
    "# characters after the given number of characters in the single \n",
    "# line has been reached.\n",
    "file = FAKER.pdf_file(content=TEMPLATE, wrap_chars_after=80)\n",
    "\n",
    "print(file)\n",
    "print(file.data[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archive types\n",
    "#### ZIP archive containing 5 TXT files\n",
    "As you might have noticed, some archive types are also supported.\n",
    "The created archive will contain 5 files in TXT format (defaults)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/tmpnmjabh3p.zip\n",
      "{'inner': {'tmp/tmpgwt9ck8_.txt': 'tmp/tmpgwt9ck8_.txt', 'tmp/tmphi4ka2n_.txt': 'tmp/tmphi4ka2n_.txt', 'tmp/tmpni20t7bq.txt': 'tmp/tmpni20t7bq.txt', 'tmp/tmp8bdgpzik.txt': 'tmp/tmp8bdgpzik.txt', 'tmp/tmps227jr99.txt': 'tmp/tmps227jr99.txt'}, 'files': [PosixPath('tmpgwt9ck8_.txt'), PosixPath('tmphi4ka2n_.txt'), PosixPath('tmpni20t7bq.txt'), PosixPath('tmp8bdgpzik.txt'), PosixPath('tmps227jr99.txt')], 'filename': '/tmp/tmp/tmpnmjabh3p.zip'}\n"
     ]
    }
   ],
   "source": [
    "from faker_file.providers.zip_file import ZipFileProvider\n",
    "\n",
    "FAKER.add_provider(ZipFileProvider)\n",
    "\n",
    "file = FAKER.zip_file()\n",
    "\n",
    "print(file)\n",
    "print(file.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested ZIP archive\n",
    "And of course nested archives are supported too. Create a `ZIP` file which\n",
    "contains 5 `ZIP` files which contain 5 `ZIP` files which contain 2 `DOCX`\n",
    "files.\n",
    "\n",
    "- 5 `ZIP` files in the `ZIP` archive.\n",
    "- Content is generated from template.\n",
    "- Prefix the filenames in archive with ``nested_level_1_``.\n",
    "- Prefix the filename of the archive itself with ``nested_level_0_``.\n",
    "- Each of the `ZIP` files inside the `ZIP` file in their turn contains 5 other `ZIP`\n",
    "  files, prefixed with ``nested_level_2_``, which in their turn contain 2\n",
    "  DOCX files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/nested_level_0_lqdw662c.zip\n",
      "{'inner': {'tmp/nested_level_1_bm4zxgup.zip': 'tmp/nested_level_1_bm4zxgup.zip', 'tmp/nested_level_1_6ftwrh0m.zip': 'tmp/nested_level_1_6ftwrh0m.zip', 'tmp/nested_level_1_p8qpnqc_.zip': 'tmp/nested_level_1_p8qpnqc_.zip', 'tmp/nested_level_1_1xqj4gfl.zip': 'tmp/nested_level_1_1xqj4gfl.zip', 'tmp/nested_level_1_xxmhig2e.zip': 'tmp/nested_level_1_xxmhig2e.zip'}, 'files': [PosixPath('nested_level_1_bm4zxgup.zip'), PosixPath('nested_level_1_6ftwrh0m.zip'), PosixPath('nested_level_1_p8qpnqc_.zip'), PosixPath('nested_level_1_1xqj4gfl.zip'), PosixPath('nested_level_1_xxmhig2e.zip')], 'filename': '/tmp/tmp/nested_level_0_lqdw662c.zip'}\n"
     ]
    }
   ],
   "source": [
    "from faker_file.providers.helpers.inner import (\n",
    "    create_inner_docx_file, \n",
    "    create_inner_zip_file,\n",
    ")\n",
    "\n",
    "file = FAKER.zip_file(\n",
    "    prefix=\"nested_level_0_\",\n",
    "    options={\n",
    "        \"create_inner_file_func\": create_inner_zip_file,\n",
    "        \"create_inner_file_args\": {\n",
    "            \"prefix\": \"nested_level_1_\",\n",
    "            \"options\": {\n",
    "                \"create_inner_file_func\": create_inner_zip_file,\n",
    "                \"create_inner_file_args\": {\n",
    "                    \"prefix\": \"nested_level_2_\",\n",
    "                    \"options\": {\n",
    "                        \"count\": 2,\n",
    "                        \"create_inner_file_func\": create_inner_docx_file,\n",
    "                        \"create_inner_file_args\": {\n",
    "                            \"content\": TEMPLATE,\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "print(file)\n",
    "print(file.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another way to create a ZIP file with fixed variety of different file types within\n",
    "- 3 files in the ZIP archive (1 DOCX, and 2 XML types).\n",
    "- Content is generated dynamically.\n",
    "- Filename of the archive itself is alice-looking-through-the-glass.zip.\n",
    "- Files inside the archive have fixed name (passed with basename argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/alice-looking-through-the-glass.zip\n",
      "{'inner': {'tmp/doc.docx': 'tmp/doc.docx', 'tmp/doc_metadata.xml': 'tmp/doc_metadata.xml', 'tmp/doc_isbn.xml': 'tmp/doc_isbn.xml'}, 'files': [PosixPath('doc.docx'), PosixPath('doc_metadata.xml'), PosixPath('doc_isbn.xml')], 'filename': '/tmp/tmp/alice-looking-through-the-glass.zip'}\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "from faker_file.providers.helpers.inner import (\n",
    "    create_inner_docx_file,\n",
    "    create_inner_xml_file,\n",
    "    list_create_inner_file,\n",
    ")\n",
    "from faker_file.providers.zip_file import ZipFileProvider\n",
    "from faker_file.storages.filesystem import FileSystemStorage\n",
    "\n",
    "FAKER = Faker()\n",
    "STORAGE = FileSystemStorage()\n",
    "\n",
    "kwargs = {\"storage\": STORAGE, \"generator\": FAKER}\n",
    "file = ZipFileProvider(FAKER).zip_file(\n",
    "    basename=\"alice-looking-through-the-glass\",\n",
    "    options={\n",
    "        \"create_inner_file_func\": list_create_inner_file,\n",
    "        \"create_inner_file_args\": {\n",
    "            \"func_list\": [\n",
    "                (create_inner_docx_file, {\"basename\": \"doc\"}),\n",
    "                (create_inner_xml_file, {\"basename\": \"doc_metadata\"}),\n",
    "                (create_inner_xml_file, {\"basename\": \"doc_isbn\"}),\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "print(file)\n",
    "print(file.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using raw=True features in tests\n",
    "If you pass raw=True argument to any provider or inner function, instead of creating a file, you will get bytes back (or to be totally correct, bytes-like object BytesValue, which is basically bytes enriched with meta-data). You could then use the bytes content of the file to build a test payload as shown in the example test below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "from django.test import TestCase\n",
    "from django.urls import reverse\n",
    "from faker import Faker\n",
    "from faker_file.providers.docx_file import DocxFileProvider\n",
    "from rest_framework.status import HTTP_201_CREATED\n",
    "from upload.models import Upload\n",
    "\n",
    "FAKER = Faker()\n",
    "FAKER.add_provider(DocxFileProvider)\n",
    "\n",
    "class UploadTestCase(TestCase):\n",
    "    \"\"\"Upload test case.\"\"\"\n",
    "\n",
    "    def test_create_docx_upload(self) -> None:\n",
    "        \"\"\"Test create an Upload.\"\"\"\n",
    "        url = reverse(\"api:upload-list\")\n",
    "\n",
    "        raw = FAKER.docx_file(raw=True)\n",
    "        test_file = BytesIO(raw)\n",
    "        test_file.name = os.path.basename(raw.data[\"filename\"])\n",
    "\n",
    "        payload = {\n",
    "            \"name\": FAKER.word(),\n",
    "            \"description\": FAKER.paragraph(),\n",
    "            \"file\": test_file,\n",
    "        }\n",
    "\n",
    "        response = self.client.post(url, payload, format=\"json\")\n",
    "\n",
    "        # Test if request is handled properly (HTTP 201)\n",
    "        self.assertEqual(response.status_code, HTTP_201_CREATED)\n",
    "\n",
    "        test_upload = Upload.objects.get(id=response.data[\"id\"])\n",
    "\n",
    "        # Test if the name is properly recorded\n",
    "        self.assertEqual(str(test_upload.name), payload[\"name\"])\n",
    "\n",
    "        # Test if file name recorded properly\n",
    "        self.assertEqual(str(test_upload.file.name), test_file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storages\n",
    "\n",
    "#### Example usage with `Django` (using local file system storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/tmpin03jrur.txt\n",
      "/home/artur.local/repos/faker-file/examples/django_example/project/media/tmp/tmpin03jrur.txt\n",
      "\n",
      "“The Queen of Hearts, she made some tarts,\n",
      "    All on a summer day:\n",
      "The Knave of Hearts, he stole those tarts,\n",
      "    And took them quite away.”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from django.conf import settings\n",
    "from faker_file.providers.txt_file import TxtFileProvider\n",
    "from faker_file.storages.filesystem import FileSystemStorage\n",
    "\n",
    "STORAGE = FileSystemStorage(\n",
    "    root_path=settings.MEDIA_ROOT,\n",
    "    rel_path=\"tmp\",\n",
    ")\n",
    "\n",
    "FAKER.add_provider(TxtFileProvider)\n",
    "\n",
    "file = FAKER.txt_file(content=TEXT, storage=STORAGE)\n",
    "\n",
    "print(file)\n",
    "print(file.data[\"filename\"])\n",
    "print(file.data[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage with AWS S3 storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO 2023-07-21 18:48:31,362 [/home/artur.local/.virtualenvs/faker-file/lib/python3.10/site-packages/botocore/credentials.py:1251] Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (InvalidAccessKeyId) when calling the CreateBucket operation: The AWS Access Key Id you provided does not exist in our records.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfaker_file\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maws_s3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AWSS3Storage\n\u001b[0;32m----> 3\u001b[0m S3_STORAGE \u001b[38;5;241m=\u001b[39m \u001b[43mAWSS3Storage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43martur-testing-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Optional\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msub-tmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Optional\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Credentials are optional too. If your AWS credentials are properly\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# set in the ~/.aws/credentials, you don't need to send them\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# explicitly.\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# credentials={\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     \"key_id\": \"YOUR KEY ID\",\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     \"key_secret\": \"YOUR KEY SECRET\"\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# },\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m file \u001b[38;5;241m=\u001b[39m FAKER\u001b[38;5;241m.\u001b[39mtxt_file(storage\u001b[38;5;241m=\u001b[39mS3_STORAGE)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(file)\n",
      "File \u001b[0;32m~/repos/faker-file/src/faker_file/storages/cloud.py:54\u001b[0m, in \u001b[0;36mCloudStorage.__init__\u001b[0;34m(self, bucket_name, root_path, rel_path, credentials, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# If bucket does not exist, create\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbucket\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/faker-file/lib/python3.10/site-packages/pathy/__init__.py:816\u001b[0m, in \u001b[0;36mPathy.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbucket\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBucket \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbucket))\n\u001b[0;32m--> 816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok:\n",
      "File \u001b[0;32m~/.virtualenvs/faker-file/lib/python3.10/site-packages/pathy/__init__.py:241\u001b[0m, in \u001b[0;36mBucketClient.mkdir\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    239\u001b[0m bucket: Optional[Bucket] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookup_bucket(path)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bucket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m bucket\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_bucket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/faker-file/lib/python3.10/site-packages/pathy/s3.py:143\u001b[0m, in \u001b[0;36mBucketClientS3.create_bucket\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_bucket\u001b[39m(  \u001b[38;5;66;03m# type:ignore[override]\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m, path: PurePathy\n\u001b[1;32m    142\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m S3NativeBucket:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_bucket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/faker-file/lib/python3.10/site-packages/botocore/client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/faker-file/lib/python3.10/site-packages/botocore/client.py:960\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    959\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (InvalidAccessKeyId) when calling the CreateBucket operation: The AWS Access Key Id you provided does not exist in our records."
     ]
    }
   ],
   "source": [
    "from faker_file.storages.aws_s3 import AWSS3Storage\n",
    "\n",
    "S3_STORAGE = AWSS3Storage(\n",
    "    bucket_name=\"artur-testing-1\",\n",
    "    root_path=\"tmp\",  # Optional\n",
    "    rel_path=\"sub-tmp\",  # Optional\n",
    "    # Credentials are optional too. If your AWS credentials are properly\n",
    "    # set in the ~/.aws/credentials, you don't need to send them\n",
    "    # explicitly.\n",
    "    # credentials={\n",
    "    #     \"key_id\": \"YOUR KEY ID\",\n",
    "    #     \"key_secret\": \"YOUR KEY SECRET\"\n",
    "    # },\n",
    ")\n",
    "\n",
    "file = FAKER.txt_file(storage=S3_STORAGE)\n",
    "\n",
    "print(file)\n",
    "print(file.data[\"filename\"])\n",
    "print(file.data[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment existing files\n",
    "If you think `Faker` generated data doesn't make sense for you and you want\n",
    "your files to look like a collection of 100 files you already have, you could\n",
    "use augmentation features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/me/Documents/faker_file_source/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfaker_file\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproviders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugment_file_from_dir\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     AugmentFileFromDirProvider,\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m FAKER\u001b[38;5;241m.\u001b[39madd_provider(AugmentFileFromDirProvider)\n\u001b[0;32m----> 7\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mFAKER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment_file_from_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_dir_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/me/Documents/faker_file_source/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrap_chars_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(file\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/repos/faker-file/src/faker_file/providers/augment_file_from_dir/__init__.py:190\u001b[0m, in \u001b[0;36mAugmentFileFromDirProvider.augment_file_from_dir\u001b[0;34m(self, source_dir_path, extensions, storage, basename, prefix, wrap_chars_after, text_extractor_cls, text_extractor_kwargs, text_augmenter_cls, text_augmenter_kwargs, raw, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m     extensions \u001b[38;5;241m=\u001b[39m EXTENSIONS\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# Specific\u001b[39;00m\n\u001b[1;32m    188\u001b[0m source_file_choices \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    189\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(source_dir_path, _f)\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_dir_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    192\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(source_dir_path, _f))\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(_f)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;129;01min\u001b[39;00m extensions\n\u001b[1;32m    194\u001b[0m     )\n\u001b[1;32m    195\u001b[0m ]\n\u001b[1;32m    196\u001b[0m source_file_path \u001b[38;5;241m=\u001b[39m choice(source_file_choices)\n\u001b[1;32m    197\u001b[0m source_file \u001b[38;5;241m=\u001b[39m Path(source_file_path)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/me/Documents/faker_file_source/'"
     ]
    }
   ],
   "source": [
    "from faker_file.providers.augment_file_from_dir import (\n",
    "    AugmentFileFromDirProvider,\n",
    ")\n",
    "\n",
    "FAKER.add_provider(AugmentFileFromDirProvider)\n",
    "\n",
    "file = FAKER.augment_file_from_dir(\n",
    "    source_dir_path=\"/home/me/Documents/faker_file_source/\",\n",
    "    wrap_chars_after=120,\n",
    ")\n",
    "\n",
    "print(file)\n",
    "print(file.data[\"filename\"])\n",
    "print(file.data[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLI\n",
    "Even if you're not using automated testing, but still want to quickly generate a file with fake content, you could use faker-file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated bash completion file: /home/artur.local/faker_file_completion.sh\r\n"
     ]
    }
   ],
   "source": [
    "  !faker-file generate-completion\n",
    "  !source ~/faker_file_completion.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate an MP3 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated mp3_file file (1 of 1): /tmp/tmp/my_file_o9f0cnge.mp3\r\n"
     ]
    }
   ],
   "source": [
    "!faker-file mp3_file --prefix=my_file_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 10 DOCX files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated docx_file file (1 of 10): /tmp/tmp/my_file_waufeho1.docx\n",
      "Generated docx_file file (2 of 10): /tmp/tmp/my_file_yjolbr1j.docx\n",
      "Generated docx_file file (3 of 10): /tmp/tmp/my_file_sj8t7nvk.docx\n",
      "Generated docx_file file (4 of 10): /tmp/tmp/my_file_pckv2iw2.docx\n",
      "Generated docx_file file (5 of 10): /tmp/tmp/my_file_xp010l8p.docx\n",
      "Generated docx_file file (6 of 10): /tmp/tmp/my_file_95e1wxtu.docx\n",
      "Generated docx_file file (7 of 10): /tmp/tmp/my_file_6zm1i44p.docx\n",
      "Generated docx_file file (8 of 10): /tmp/tmp/my_file_9xxngwtp.docx\n",
      "Generated docx_file file (9 of 10): /tmp/tmp/my_file_ekfoi04l.docx\n",
      "Generated docx_file file (10 of 10): /tmp/tmp/my_file_lg_7qm1q.docx\n"
     ]
    }
   ],
   "source": [
    "!faker-file docx_file --nb_files 10 --prefix=my_file_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demos\n",
    "\n",
    "There are some online demos for you to play around:\n",
    "    \n",
    "- REST API demo, based on FastAPI: https://faker-file-api.onrender.com/docs/\n",
    "- UI frontend demo, based on React: https://faker-file-ui.vercel.app/\n",
    "- WASM demo: https://faker-file-wasm.vercel.app/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "\n",
    "- Documentation: http://faker-file.readthedocs.io/\n",
    "- GitHub: https://github.com/barseghyanartur/faker-file\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Kernel",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
