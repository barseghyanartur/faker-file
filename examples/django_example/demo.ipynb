{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Generate a `DOCX` file with fake content\n",
    "- Generate 1 `DOCX` file with fake content (generated by `Faker`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/tmppagn9gzf.docx\n",
      "/tmp/tmp/tmppagn9gzf.docx\n",
      "Result majority however improve better fast poor. Though reduce board. Do board development break develop.\n",
      "House bring public knowledge seem. Run here head identify establish risk recent institution. Authority agreement program threat individual onto few.\n",
      "Service deal success worker game public cell. Purpose service make fear.\n",
      "Computer term daughter. Policy citizen move eye.\n",
      "Total law determine cold activity. Congress value collection near.\n",
      "Traditional apply probably high. Customer hotel treatment computer. Modern visit culture true end kind seem.\n",
      "Important lose cell southern evidence decade computer. Letter possible important move thank future suggest. But government professional listen.\n",
      "Sister might wall. Understand seven site sport whose run morning. Star space save than.\n",
      "Generation continue task when reduce administration quality. State project Mrs.\n",
      "Movement enter why analysis cultural follow. Suggest human rule same if research ten senior. Carry hear human keep fast.\n",
      "Home name quite front produce. Present light bank benefit drug assume month. Majority range somebody along effort peace.\n",
      "Necessary town because maybe thousand begin assume. Must manage live growth. Animal service could. Tell spring wonder position young yard training.\n",
      "Try spring like different arrive. Growth significant arrive hard my.\n",
      "News even west of. Relationship federal resource peace law public. Drop PM notice plan up sometimes establish.\n",
      "Out contain investment. Hand third set find themselves hit. Another away available leave free smile message allow.\n",
      "Well bar next set most professional. Argue Democrat fill ok media another price.\n",
      "Trade add bed eat page several treatment reduce. Nature face medical here ready energy must.\n",
      "International throughout owner less identify finally lay. Short hit mention dinner energy trouble deep. Land stop bring quickly say and international care.\n",
      "Majority call rule source yeah. Relationship early water. Participant start defense health. Education act game certainly less.\n",
      "Than environment business successful feeling keep responsibility. What increase data end seem sign speak hold. Fight past practice whatever dream open environment.\n",
      "Attack moment knowledge say around table. I prepare option down dream. Of than plant generation goal it.\n",
      "Start difficult hear increase wall cultural company interest. While plan be technology likely author.\n",
      "Figure building year account yard maintain. Strong reach simply in.\n",
      "Agreement open city class citizen property leave. Contain group economy computer point put while. Type person senior customer.\n",
      "Relationship hit key mind whose know.\n",
      "Lawyer real machine surface a place state rather. Man recent occur old wish commercial dog. Think between ball natural face score.\n",
      "Answer poor change. Or fill claim receive. Occur enough remain owner about position major.\n",
      "Voice ready yard pressure here my. Economy race last today let cause just. Himself before action data force page. Meeting record contain present.\n",
      "To message with certain run leave. Process owner smile large rather center. Discuss prove vote our lot keep.\n",
      "Education sport which college remember. Attorney less Mr drive woman stage.\n",
      "Have among say plant third table. Conference run seek with. Eye little wear occur.\n",
      "Soon police tough pick half ever. Share law road production create finally green past.\n",
      "Research who guess against full mean. Third every campaign deep. Administration after know maybe.\n",
      "There offer from since. Note budget cell cause will doctor.\n",
      "Common artist whole season. Series tax reflect idea last.\n",
      "Enough hot unit worry course central. Senior open price.\n",
      "Civil go own office baby bit good. Class true fine lot brother some tax.\n",
      "Line rather simple star itself benefit. Look history art together medical meet. One get must star him left.\n",
      "Rise wife street. Occur side rate house contain. Piece husband own popular ok.\n",
      "Leader rather choose scene somebody. Lose be property over language wear.\n",
      "Along reality speak knowledge system company explain. Run key although challenge admit miss. Chair issue since difference heavy measure cell.\n",
      "Hotel I head success book. Relate those democratic mind answer store human. Individual also high wall.\n",
      "Often human second. Good together friend practice dinner successful room. Price somebody front boy air blue.\n",
      "Discussion into party star pull above. Mr discover also drug because product beat. Employee service toward majority common daughter low need. Leg behind capital billion huge sing this.\n",
      "Change federal listen according wind. Treat spend goal represent education seem young. Sing president interview.\n",
      "Benefit stop edge decade wear serve wide. Consider son paper hold TV see. Use along arm sit food particular six.\n",
      "Reason pretty eight choice. Image office station stay television. Customer beautiful worker nor knowledge nation. Move traditional clearly happen left thank present.\n",
      "Woman book fear approach purpose company travel nothing. Image message similar interesting computer hope.\n",
      "Material director others phone.\n",
      "Focus figure so big effort election. Whom national truth same that position. Hit set challenge head activity new.\n",
      "Or future pay pressure floor item I. Street might wonder pressure soon nature shoulder shake.\n",
      "Explain economic college man fund. On entire appear positive star. Ahead phone six himself.\n",
      "Health fall husband. Lead might prepare important seven between brother. Blood day whose culture business.\n",
      "Believe behavior almost fund free remain. Lot still shake assume. Lead design people build oil catch.\n",
      "Anyone fund catch player suffer send well save. Music tonight or ago. However data if can.\n",
      "Beyond well great garden recognize. Before training force deep.\n",
      "Defense responsibility trade establish million life media service. Pull task word soldier. Job ask because ground evidence.\n",
      "Here senior few already month voice onto. Minute could film fire consider station. Would big program door quite.\n",
      "People agreement treat sea without feel manager. Goal street husband important. Garden see must.\n",
      "Street fish building their himself. Enough sell run approach range agency hundred. Trade people account either fact.\n",
      "Project state after. Military couple music media television assume herself. Short white ten under religious half. Drive result minute letter watch.\n",
      "Energy whatever sister shoulder down federal every sense. Table from girl somebody there. Study read but part learn hot choice.\n",
      "Pick would give after national magazine smile. Crime sometimes cause behavior may. Once with itself book hear important all. Several picture pressure pressure safe certain.\n",
      "Event training say ready race trouble scene suddenly. Number choice season able shoulder approach compare stay. Main phone speech rule little international side able.\n",
      "Minute capital leave voice city later before. Sister rock move news policy. Every perform especially finish little recognize.\n",
      "Accept success today walk put score follow. Believe create instead organization.\n",
      "Beyond film design win. Society really together Republican kitchen second anyone.\n",
      "Improve doctor military near trial. Discover stay court. Walk east kitchen field teach house somebody read.\n",
      "Ball agree late also citizen should. Onto growth site white. World anything size garden only practice.\n",
      "Natural heart beat choose bag yeah yes item. Mouth relate region them.\n",
      "College major character need. Idea discover amount budget data see. Issue available worker example.\n",
      "Feeling pass business national service bill. Least sense explain writer word democratic young. Put dark write fund.\n",
      "Same structure music article force. Force member drug tree stand about good.\n",
      "Car charge information time individual the. East know develop more.\n",
      "Trouble address myself personal movie oil energy. Opportunity night while technology door without.\n",
      "Sport which save indeed. Son development pull couple we.\n",
      "Herself expert within put. Finish green official send room.\n",
      "Account almost any only. However care space design. Trouble score shoulder clearly poor increase production. Accept player ago relate leader.\n",
      "Final about several just board. Computer structure tell Mrs ask.\n",
      "No yourself citizen. Music address group hospital man seem arrive medical.\n",
      "East college fear plant. Strategy lead federal television bar environment try heavy.\n",
      "Us story identify between rise. Ahead TV onto marriage whole.\n",
      "Natural food it about himself decide wrong. Peace stock community yet across. Add else success family.\n",
      "Tax executive business institution. Agent indeed finish able. Participant happen agree. Or country better down.\n",
      "At area what environmental else style language within. Wear answer community health. Statement accept place in fish.\n",
      "Consumer second actually three pick method check. Challenge yes media. Because great eat talk.\n",
      "For leave high. Plan with vote then option. Buy option concern last teach off than. Subject audience once task success situation where building.\n",
      "Direction in born.\n",
      "Sometimes popular drug rich size. Let attention remain better. Anything among part red. Run station brother her.\n",
      "Cup director modern. Perform arm owner. Street difficult management thing political.\n",
      "Stop public heart ago interesting. Energy rock action admit soldier even environmental. Class public southern stage thousand million.\n",
      "Body investment bill star huge white great. Recently turn understand finish.\n",
      "Rich others lawyer fund talk goal break. Increase color move suddenly memory.\n",
      "Day develop role charge. Appear society while. Energy training threat evidence.\n",
      "Agree group game little. Figure sit wife civil better style involve believe.\n",
      "Mean day drug pressure school almost drop. Meet morning movie age wrong large heart.\n",
      "American would mother tax even approach. Still letter push source thousand right prevent.\n",
      "Smile state someone say while. Early time nice goal lose explain. Close appear population government first.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System environmental can avoid. Community create item plan can.\n"
     ]
    }
   ],
   "source": [
    "# Import the Faker class from faker package\n",
    "from faker import Faker\n",
    "\n",
    "# Import the file provider we want to use\n",
    "from faker_file.providers.docx_file import DocxFileProvider\n",
    "\n",
    "FAKER = Faker()  # Initialise Faker instance\n",
    "\n",
    "FAKER.add_provider(DocxFileProvider)  # Register the DOCX file provider\n",
    "\n",
    "file = FAKER.docx_file()  # Generate a DOCX file\n",
    "\n",
    "# This is just a string-like value, with a relative path to the file\n",
    "print(file)\n",
    "\n",
    "# Note, that `file` is this case is an instance of either `StringValue`\n",
    "# or `BytesValue` objects, which inherit from `str` and `bytes`\n",
    "# respectively, but add meta data. Meta data is stored inside the `data`\n",
    "# property (`Dict`). One of the common attributes of which (among all\n",
    "# file providers) is the `filename`, which holds an absolute path to the\n",
    "# generated file.\n",
    "print(file.data[\"filename\"])\n",
    "\n",
    "# Another common attribute (although it's not available for all providers)\n",
    "# is `content`, which holds the text used to generate the file with.\n",
    "print(file.data[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide content manually\n",
    "- Generate 1 `DOCX` file with developer defined content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/tmpi89l5oug.docx\n",
      "\n",
      "“The Queen of Hearts, she made some tarts,\n",
      "    All on a summer day:\n",
      "The Knave of Hearts, he stole those tarts,\n",
      "    And took them quite away.”\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"\"\"\n",
    "“The Queen of Hearts, she made some tarts,\n",
    "    All on a summer day:\n",
    "The Knave of Hearts, he stole those tarts,\n",
    "    And took them quite away.”\n",
    "\"\"\"\n",
    "\n",
    "file = FAKER.docx_file(content=TEXT)\n",
    "\n",
    "print(file)\n",
    "print(file.data[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Similarly, generate 1 `PNG` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker_file.providers.png_file import PngFileProvider\n",
    "\n",
    "FAKER.add_provider(PngFileProvider)\n",
    "\n",
    "file = FAKER.png_file()\n",
    "\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Similarly, generate 1 `PDF` file. Limit the line width to 80 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker_file.providers.pdf_file import PdfFileProvider\n",
    "\n",
    "FAKER.add_provider(PdfFileProvider)\n",
    "\n",
    "file = FAKER.pdf_file(wrap_chars_after=80)\n",
    "\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide templated content\n",
    "\n",
    "You can generate documents from pre-defined templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "{{date}} {{city}}, {{country}}\n",
    "\n",
    "Hello {{name}},\n",
    "\n",
    "{{text}}\n",
    "\n",
    "Address: {{address}}\n",
    "\n",
    "Best regards,\n",
    "\n",
    "{{name}}\n",
    "{{address}}\n",
    "{{phone_number}}\n",
    "\"\"\"\n",
    "\n",
    "file = FAKER.pdf_file(content=TEMPLATE, wrap_chars_after=80)\n",
    "\n",
    "print(file)\n",
    "print(file.data[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archive types\n",
    "#### ZIP archive containing 5 TXT files\n",
    "As you might have noticed, some archive types are also supported.\n",
    "The created archive will contain 5 files in TXT format (defaults)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker_file.providers.zip_file import ZipFileProvider\n",
    "\n",
    "FAKER.add_provider(ZipFileProvider)\n",
    "\n",
    "file = FAKER.zip_file()\n",
    "\n",
    "print(file)\n",
    "print(file.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ZIP archive containing 3 DOCX files with text generated from a template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker_file.providers.helpers.inner import create_inner_docx_file\n",
    "\n",
    "file = FAKER.zip_file(\n",
    "    prefix=\"zzz\",\n",
    "    options={\n",
    "        \"count\": 3,\n",
    "        \"create_inner_file_func\": create_inner_docx_file,\n",
    "        \"create_inner_file_args\": {\n",
    "            \"prefix\": \"xxx_\",\n",
    "            \"content\": TEMPLATE,\n",
    "        },\n",
    "        \"directory\": \"yyy\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(file)\n",
    "print(file.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested ZIP archive\n",
    "And of course nested archives are supported too. Create a `ZIP` file which\n",
    "contains 5 `ZIP` files which contain 5 `ZIP` files which contain 2 `DOCX`\n",
    "files.\n",
    "\n",
    "- 5 `ZIP` files in the `ZIP` archive.\n",
    "- Content is generated dynamically.\n",
    "- Prefix the filenames in archive with ``nested_level_1_``.\n",
    "- Prefix the filename of the archive itself with ``nested_level_0_``.\n",
    "- Each of the `ZIP` files inside the `ZIP` file in their turn contains 5 other `ZIP`\n",
    "  files, prefixed with ``nested_level_2_``, which in their turn contain 2\n",
    "  DOCX files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker_file.providers.helpers.inner import create_inner_zip_file\n",
    "\n",
    "file = FAKER.zip_file(\n",
    "    prefix=\"nested_level_0_\",\n",
    "    options={\n",
    "        \"create_inner_file_func\": create_inner_zip_file,\n",
    "        \"create_inner_file_args\": {\n",
    "            \"prefix\": \"nested_level_1_\",\n",
    "            \"options\": {\n",
    "                \"create_inner_file_func\": create_inner_zip_file,\n",
    "                \"create_inner_file_args\": {\n",
    "                    \"prefix\": \"nested_level_2_\",\n",
    "                    \"options\": {\n",
    "                        \"count\": 2,\n",
    "                        \"create_inner_file_func\": create_inner_docx_file,\n",
    "                        \"create_inner_file_args\": {\n",
    "                            \"content\": TEXT + \"\\n\\n{{date}}\",\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "print(file)\n",
    "print(file.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works similarly for `EML` files (using ``EmlFileProvider``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker_file.providers.eml_file import EmlFileProvider\n",
    "from faker_file.providers.helpers.inner import create_inner_docx_file\n",
    "\n",
    "FAKER.add_provider(EmlFileProvider)\n",
    "\n",
    "file = FAKER.eml_file(\n",
    "    prefix=\"zzz\",\n",
    "    content=TEMPLATE,\n",
    "    options={\n",
    "        \"count\": 3,\n",
    "        \"create_inner_file_func\": create_inner_docx_file,\n",
    "        \"create_inner_file_args\": {\n",
    "            \"prefix\": \"xxx_\",\n",
    "            \"content\": TEXT + \"\\n\\n{{date}}\",\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "print(file)\n",
    "print(file.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a ZIP file with random variety of different file types within\n",
    "- 50 files in the ZIP archive (limited to DOCX, EPUB and TXT types).\n",
    "- Content is generated dynamically.\n",
    "- Prefix the filename of the archive itself with zzz_archive_.\n",
    "- Inside the ZIP, put all files in directory zzz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "from faker_file.providers.helpers.inner import (\n",
    "    create_inner_docx_file,\n",
    "    create_inner_epub_file,\n",
    "    create_inner_txt_file,\n",
    "    fuzzy_choice_create_inner_file,\n",
    ")\n",
    "from faker_file.providers.zip_file import ZipFileProvider\n",
    "from faker_file.storages.filesystem import FileSystemStorage\n",
    "\n",
    "FAKER = Faker()\n",
    "STORAGE = FileSystemStorage()\n",
    "\n",
    "kwargs = {\"storage\": STORAGE, \"generator\": FAKER}\n",
    "file = ZipFileProvider(FAKER).zip_file(\n",
    "    prefix=\"zzz_archive_\",\n",
    "    options={\n",
    "        \"count\": 50,\n",
    "        \"create_inner_file_func\": fuzzy_choice_create_inner_file,\n",
    "        \"create_inner_file_args\": {\n",
    "            \"func_choices\": [\n",
    "                (create_inner_docx_file, kwargs),\n",
    "                (create_inner_epub_file, kwargs),\n",
    "                (create_inner_txt_file, kwargs),\n",
    "            ],\n",
    "        },\n",
    "        \"directory\": \"zzz\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(file)\n",
    "print(file.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another way to create a ZIP file with fixed variety of different file types within\n",
    "- 3 files in the ZIP archive (1 DOCX, and 2 XML types).\n",
    "- Content is generated dynamically.\n",
    "- Filename of the archive itself is alice-looking-through-the-glass.zip.\n",
    "- Files inside the archive have fixed name (passed with basename argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "from faker_file.providers.helpers.inner import (\n",
    "    create_inner_docx_file,\n",
    "    create_inner_xml_file,\n",
    "    list_create_inner_file,\n",
    ")\n",
    "from faker_file.providers.zip_file import ZipFileProvider\n",
    "from faker_file.storages.filesystem import FileSystemStorage\n",
    "\n",
    "FAKER = Faker()\n",
    "STORAGE = FileSystemStorage()\n",
    "\n",
    "kwargs = {\"storage\": STORAGE, \"generator\": FAKER}\n",
    "file = ZipFileProvider(FAKER).zip_file(\n",
    "    basename=\"alice-looking-through-the-glass\",\n",
    "    options={\n",
    "        \"create_inner_file_func\": list_create_inner_file,\n",
    "        \"create_inner_file_args\": {\n",
    "            \"func_list\": [\n",
    "                (create_inner_docx_file, {\"basename\": \"doc\"}),\n",
    "                (create_inner_xml_file, {\"basename\": \"doc_metadata\"}),\n",
    "                (create_inner_xml_file, {\"basename\": \"doc_isbn\"}),\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "print(file)\n",
    "print(file.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using raw=True features in tests\n",
    "If you pass raw=True argument to any provider or inner function, instead of creating a file, you will get bytes back (or to be totally correct, bytes-like object BytesValue, which is basically bytes enriched with meta-data). You could then use the bytes content of the file to build a test payload as shown in the example test below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "from django.test import TestCase\n",
    "from django.urls import reverse\n",
    "from faker import Faker\n",
    "from faker_file.providers.docx_file import DocxFileProvider\n",
    "from rest_framework.status import HTTP_201_CREATED\n",
    "from upload.models import Upload\n",
    "\n",
    "FAKER = Faker()\n",
    "FAKER.add_provider(DocxFileProvider)\n",
    "\n",
    "class UploadTestCase(TestCase):\n",
    "    \"\"\"Upload test case.\"\"\"\n",
    "\n",
    "    def test_create_docx_upload(self) -> None:\n",
    "        \"\"\"Test create an Upload.\"\"\"\n",
    "        url = reverse(\"api:upload-list\")\n",
    "\n",
    "        raw = FAKER.docx_file(raw=True)\n",
    "        test_file = BytesIO(raw)\n",
    "        test_file.name = os.path.basename(raw.data[\"filename\"])\n",
    "\n",
    "        payload = {\n",
    "            \"name\": FAKER.word(),\n",
    "            \"description\": FAKER.paragraph(),\n",
    "            \"file\": test_file,\n",
    "        }\n",
    "\n",
    "        response = self.client.post(url, payload, format=\"json\")\n",
    "\n",
    "        # Test if request is handled properly (HTTP 201)\n",
    "        self.assertEqual(response.status_code, HTTP_201_CREATED)\n",
    "\n",
    "        test_upload = Upload.objects.get(id=response.data[\"id\"])\n",
    "\n",
    "        # Test if the name is properly recorded\n",
    "        self.assertEqual(str(test_upload.name), payload[\"name\"])\n",
    "\n",
    "        # Test if file name recorded properly\n",
    "        self.assertEqual(str(test_upload.file.name), test_file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a HTML file predefined template\n",
    "If you want to generate a file in a format that is not (yet) supported, you can try to use `GenericFileProvider`. In the following example, an HTML file is generated from a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "from faker_file.providers.generic_file import GenericFileProvider\n",
    "\n",
    "file = GenericFileProvider(Faker()).generic_file(\n",
    "    content=\"<html><body><p>{{text}}</p></body></html>\",\n",
    "    extension=\"html\",\n",
    ")\n",
    "\n",
    "print(file)\n",
    "print(file.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storages\n",
    "\n",
    "#### Example usage with `Django` (using local file system storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.conf import settings\n",
    "from faker_file.providers.txt_file import TxtFileProvider\n",
    "from faker_file.storages.filesystem import FileSystemStorage\n",
    "\n",
    "STORAGE = FileSystemStorage(\n",
    "    root_path=settings.MEDIA_ROOT,\n",
    "    rel_path=\"tmp\",\n",
    ")\n",
    "\n",
    "FAKER.add_provider(TxtFileProvider)\n",
    "\n",
    "file = FAKER.txt_file(content=TEXT, storage=STORAGE)\n",
    "\n",
    "print(file)\n",
    "print(file.data[\"filename\"])\n",
    "print(file.data[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage with AWS S3 storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker_file.storages.aws_s3 import AWSS3Storage\n",
    "\n",
    "S3_STORAGE = AWSS3Storage(\n",
    "    bucket_name=\"artur-testing-1\",\n",
    "    root_path=\"tmp\",  # Optional\n",
    "    rel_path=\"sub-tmp\",  # Optional\n",
    "    # Credentials are optional too. If your AWS credentials are properly\n",
    "    # set in the ~/.aws/credentials, you don't need to send them\n",
    "    # explicitly.\n",
    "    # credentials={\n",
    "    #     \"key_id\": \"YOUR KEY ID\",\n",
    "    #     \"key_secret\": \"YOUR KEY SECRET\"\n",
    "    # },\n",
    ")\n",
    "\n",
    "file = FAKER.txt_file(storage=S3_STORAGE)\n",
    "\n",
    "print(file)\n",
    "print(file.data[\"filename\"])\n",
    "print(file.data[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment existing files\n",
    "If you think `Faker` generated data doesn't make sense for you and you want\n",
    "your files to look like a collection of 100 files you already have, you could\n",
    "use augmentation features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker_file.providers.augment_file_from_dir import (\n",
    "    AugmentFileFromDirProvider,\n",
    ")\n",
    "\n",
    "FAKER.add_provider(AugmentFileFromDirProvider)\n",
    "\n",
    "file = FAKER.augment_file_from_dir(\n",
    "    source_dir_path=\"/home/me/Documents/faker_file_source/\",\n",
    "    wrap_chars_after=120,\n",
    ")\n",
    "\n",
    "print(file)\n",
    "print(file.data[\"filename\"])\n",
    "print(file.data[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLI\n",
    "Even if you're not using automated testing, but still want to quickly generate a file with fake content, you could use faker-file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  !faker-file generate-completion\n",
    "  !source ~/faker_file_completion.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate an MP3 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!faker-file mp3_file --prefix=my_file_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 10 DOCX files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!faker-file docx_file --nb_files 10 --prefix=my_file_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Kernel",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
